#!/usr/bin/env python3
"""
SERVICE 1: PR√âTRAITEMENT D'IMAGES/PDF
Redresse, am√©liore contraste, binarise et convertit les documents
Pour optimiser l'OCR en amont
"""

import cv2
import numpy as np
from PIL import Image
from pathlib import Path
import logging
from typing import Tuple, Optional

try:
    import pdf2image
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False

class PreprocessingService:
    """Service d√©di√© au pr√©traitement robuste d'images et PDFs"""

    def __init__(self, output_dir: str = "processed"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # Configuration logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        # Param√®tres de preprocessing
        self.min_resolution = 1000  # R√©solution minimale recommand√©e
        self.max_resolution = 3000  # R√©solution maximale (√©viter surcharge)

    def process_document(self, file_path: str) -> str:
        """Point d'entr√©e principal: traite PDF ou image"""
        file_path = Path(file_path)

        if not file_path.exists():
            raise FileNotFoundError(f"Fichier non trouv√©: {file_path}")

        self.logger.info(f"üîß Pr√©traitement: {file_path.name}")

        # Traiter selon type de fichier
        if file_path.suffix.lower() == '.pdf':
            return self._process_pdf(file_path)
        elif file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp']:
            return self._process_image(file_path)
        else:
            raise ValueError(f"Format non support√©: {file_path.suffix}")

    def _process_pdf(self, pdf_path: Path) -> str:
        """Convertir PDF en image optimis√©e"""
        if not PDF2IMAGE_AVAILABLE:
            raise ImportError("pdf2image requis pour les PDFs")

        self.logger.info(f"üìÑ Conversion PDF: {pdf_path.name}")

        try:
            # Convertir PDF en images (premi√®re page)
            pages = pdf2image.convert_from_path(
                pdf_path,
                dpi=300,  # DPI √©lev√© pour qualit√© OCR
                first_page=1,
                last_page=1,
                fmt='PNG'
            )

            if not pages:
                raise ValueError("PDF vide ou non lisible")

            # Sauvegarder temporairement
            temp_image_path = self.output_dir / f"temp_{pdf_path.stem}.png"
            pages[0].save(temp_image_path)

            # Traiter l'image convertie
            return self._process_image(temp_image_path)

        except Exception as e:
            self.logger.error(f"Erreur conversion PDF: {e}")
            raise

    def _process_image(self, image_path: Path) -> str:
        """Pipeline complet de traitement d'image"""
        self.logger.info(f"üñºÔ∏è Traitement image: {image_path.name}")

        # Charger l'image
        img = cv2.imread(str(image_path))
        if img is None:
            raise ValueError(f"Image non lisible: {image_path}")

        # Pipeline de preprocessing
        img = self._correct_perspective(img)
        img = self._optimize_resolution(img)
        img = self._enhance_contrast(img)
        img = self._enhance_sharpness(img)
        img = self._binarize_adaptive(img)
        img = self._remove_noise(img)

        # Sauvegarder r√©sultat
        output_path = self.output_dir / f"processed_{image_path.name}"
        cv2.imwrite(str(output_path), img)

        self.logger.info(f"‚úÖ Image pr√©par√©e: {output_path}")
        return str(output_path)

    def _correct_perspective(self, img: np.ndarray) -> np.ndarray:
        """Corriger la perspective si l'image est prise de biais"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img_height, img_width = gray.shape[:2]
        img_area = img_height * img_width

        # D√©tecter les contours pour trouver le document
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            self.logger.warning("Aucun contour d√©tect√© - pas de correction perspective")
            return img

        # Trouver le plus grand rectangle (probable document)
        largest_contour = max(contours, key=cv2.contourArea)
        contour_area = cv2.contourArea(largest_contour)

        # CORRECTION: Ne pas appliquer si le contour est trop petit (< 50% de l'image)
        # Cela √©vite de cropper sur une petite zone d√©tect√©e par erreur
        min_area_ratio = 0.5
        if contour_area < img_area * min_area_ratio:
            self.logger.info(f"üìê Contour trop petit ({contour_area/img_area*100:.1f}% < 50%) - pas de correction perspective")
            return img

        # Approximation polygonale
        epsilon = 0.02 * cv2.arcLength(largest_contour, True)
        approx = cv2.approxPolyDP(largest_contour, epsilon, True)

        # Si on a un quadrilat√®re, corriger la perspective
        if len(approx) == 4:
            self.logger.info("üìê Correction perspective d√©tect√©e")
            return self._apply_perspective_correction(img, approx)

        return img

    def _apply_perspective_correction(self, img: np.ndarray, corners: np.ndarray) -> np.ndarray:
        """Appliquer correction de perspective"""
        # Ordonner les coins (top-left, top-right, bottom-right, bottom-left)
        corners = corners.reshape(4, 2)
        ordered_corners = np.zeros((4, 2), dtype=np.float32)

        # Somme et diff√©rence pour identifier les coins
        s = corners.sum(axis=1)
        diff = np.diff(corners, axis=1)

        ordered_corners[0] = corners[np.argmin(s)]      # top-left
        ordered_corners[2] = corners[np.argmax(s)]      # bottom-right
        ordered_corners[1] = corners[np.argmin(diff)]   # top-right
        ordered_corners[3] = corners[np.argmax(diff)]   # bottom-left

        # Calculer dimensions de destination
        width = max(
            np.linalg.norm(ordered_corners[0] - ordered_corners[1]),
            np.linalg.norm(ordered_corners[2] - ordered_corners[3])
        )
        height = max(
            np.linalg.norm(ordered_corners[0] - ordered_corners[3]),
            np.linalg.norm(ordered_corners[1] - ordered_corners[2])
        )

        # Points de destination (rectangle parfait)
        dst_points = np.array([
            [0, 0],
            [width - 1, 0],
            [width - 1, height - 1],
            [0, height - 1]
        ], dtype=np.float32)

        # Transformation de perspective
        matrix = cv2.getPerspectiveTransform(ordered_corners, dst_points)
        corrected = cv2.warpPerspective(img, matrix, (int(width), int(height)))

        return corrected

    def _optimize_resolution(self, img: np.ndarray) -> np.ndarray:
        """Optimiser la r√©solution pour OCR"""
        height, width = img.shape[:2]
        current_resolution = min(height, width)

        if current_resolution < self.min_resolution:
            # Upscale si trop petit
            scale_factor = self.min_resolution / current_resolution
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)

            self.logger.info(f"üìà Upscale: {width}x{height} -> {new_width}x{new_height}")
            return cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)

        elif current_resolution > self.max_resolution:
            # Downscale si trop grand
            scale_factor = self.max_resolution / current_resolution
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)

            self.logger.info(f"üìâ Downscale: {width}x{height} -> {new_width}x{new_height}")
            return cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)

        return img

    def _enhance_contrast(self, img: np.ndarray) -> np.ndarray:
        """Am√©liorer le contraste avec CLAHE adaptatif"""
        # Convertir en niveaux de gris si n√©cessaire
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img.copy()

        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        self.logger.debug("üîÜ Am√©lioration contraste appliqu√©e")
        return enhanced

    def _enhance_sharpness(self, img: np.ndarray) -> np.ndarray:
        """Am√©liorer la nettet√© pour l'OCR"""
        # Kernel pour augmenter la nettet√©
        kernel = np.array([[-1, -1, -1],
                          [-1,  9, -1],
                          [-1, -1, -1]])

        sharpened = cv2.filter2D(img, -1, kernel)

        # M√©langer avec l'original pour √©viter le sur-traitement
        alpha = 0.7  # Poids de l'image nettoy√©e
        result = cv2.addWeighted(img, 1 - alpha, sharpened, alpha, 0)

        self.logger.debug("üîç Am√©lioration nettet√© appliqu√©e")
        return result

    def _binarize_adaptive(self, img: np.ndarray) -> np.ndarray:
        """Binarisation adaptative optimis√©e pour OCR"""
        # Binarisation adaptative Gaussian
        binary = cv2.adaptiveThreshold(
            img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 15, 10
        )

        # Alternative: binarisation Otsu pour comparaison
        _, binary_otsu = cv2.threshold(
            img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
        )

        # Choisir la meilleure m√©thode bas√©e sur le contraste
        adaptive_variance = np.var(binary)
        otsu_variance = np.var(binary_otsu)

        if adaptive_variance > otsu_variance:
            self.logger.debug("üéØ Binarisation adaptative s√©lectionn√©e")
            return binary
        else:
            self.logger.debug("üéØ Binarisation Otsu s√©lectionn√©e")
            return binary_otsu

    def _remove_noise(self, img: np.ndarray) -> np.ndarray:
        """Supprimer le bruit tout en pr√©servant le texte"""
        # Morphologie pour nettoyer le bruit
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))

        # Opening pour supprimer petits objets
        cleaned = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=1)

        # Closing pour fermer les gaps dans les lettres
        cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel, iterations=1)

        self.logger.debug("üßπ Suppression bruit appliqu√©e")
        return cleaned

    def get_preprocessing_stats(self, original_path: str, processed_path: str) -> dict:
        """Obtenir statistiques de pr√©traitement"""
        original = cv2.imread(original_path, cv2.IMREAD_GRAYSCALE)
        processed = cv2.imread(processed_path, cv2.IMREAD_GRAYSCALE)

        if original is None or processed is None:
            return {}

        return {
            'original_size': original.shape,
            'processed_size': processed.shape,
            'original_contrast': np.std(original),
            'processed_contrast': np.std(processed),
            'improvement_ratio': np.std(processed) / np.std(original) if np.std(original) > 0 else 1.0
        }

def main():
    """Test du service de pr√©traitement"""
    service = PreprocessingService()

    # Exemple d'utilisation
    sample_files = Path("sample_data").glob("*")

    for file_path in sample_files:
        if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.pdf']:
            try:
                processed_path = service.process_document(str(file_path))
                print(f"‚úÖ {file_path.name} -> {processed_path}")

                # Statistiques
                stats = service.get_preprocessing_stats(str(file_path), processed_path)
                if stats:
                    print(f"üìä Am√©lioration contraste: {stats['improvement_ratio']:.2f}x")

            except Exception as e:
                print(f"‚ùå Erreur {file_path.name}: {e}")

if __name__ == "__main__":
    main()